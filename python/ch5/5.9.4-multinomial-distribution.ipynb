{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch.distributions.multinomial import Multinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Distribution\n",
    "\n",
    "In the aforementioned example, we considered a dataset with only two classes - celebrities and non-celebrities. Now let us say we have a more granular dataset as follows:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> Index <td> Class <td> Percentage <td> Probability\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td> 1 <td> Albert Einstein <td> 5% <td> 0.05\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td> 2 <td> Marie Curie <td> 7% <td> 0.07\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td> 3 <td> Gauss <td> 3% <td> 0.03\n",
    "    <tr>\n",
    "    <tr>\n",
    "        <td> 4 <td> Others <td> 85 % <td> 0.85\n",
    "    <tr>\n",
    "<table>\n",
    "\n",
    "    \n",
    "Let us perform an experiment where we select 20 photos from the dataset and want to find out the probability that class1 occurs 4 times, class2 occurs 2 times, class3 occurs 3 times and class 4 occurs the remaining 11 times. We can do so using the multinomial distribution, which is an extension of the binomial distribution from 2 variables to m variables.\n",
    "    \n",
    "Formally, let $C_{1}$, $C_{2}$, ..., $C_{m}$ be $m$ classes with probabilities $p_{1}$, $p_{2}$, ..., $p_{m}$. Let $X_{1}$, $X_{2}$, ..., $X_{m}$ be the corresponding random variables in a set of $n$ trials.\n",
    "    \n",
    "Then, the multinomial probability function, depicting probability of $C_{1}$ being selected $k_{1}$ times, $C_{2}$ being selected $k_{2}$ times, $C_{m}$ being selected $k_{m}$ times is \n",
    "   $$ P(X_{1}=k_{1}, X_{2}=k_{2}, .., X_{m}=k_{m}) = \\frac{n!}{k_{1}!k_{2}!...k_{m}!} p_{1}^{k_{1}}p_{2}^{k_{2}}...p_{m}^{k_{m}} $$\n",
    "    \n",
    "where $ \\sum_{i=1}^m k_i = n$ and $ \\sum_{i=1}^m p_i = 1$\n",
    "    \n",
    "Note that for $m=2$, this becomes the binomial distribution. Now, let us implement this in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 20\n",
    "p = torch.tensor([0.05, 0.07, 0.03, 0.85], dtype=torch.float)\n",
    "k = torch.tensor([4, 2, 1, 13], dtype=torch.float)\n",
    "\n",
    "num_samples = 100000 # Number of experiment runs\n",
    "\n",
    "# Create the multinomial distribution\n",
    "multinomial_dist = Multinomial(num_trials, probs=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formula(k, n, p):\n",
    "    f = math.factorial\n",
    "    result = f(n)\n",
    "    for pi, ki in zip(p, k):\n",
    "        result *= (pi ** ki) / f(ki)\n",
    "    return torch.log(result)\n",
    "\n",
    "log_prob = multinomial_dist.log_prob(k)\n",
    "\n",
    "formula_log_prob = formula(k, num_trials, p)\n",
    "\n",
    "assert torch.isclose(log_prob, formula_log_prob, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n"
     ]
    }
   ],
   "source": [
    "# Now, we draw <num_samples> samples from the distribution. \n",
    "# Each element of the samples array represent the number of successes in that experiment.\n",
    "samples = multinomial_dist.sample(torch.Size([num_samples]))\n",
    "\n",
    "print(\"Number of samples: {}\".format(len(samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([ 1.0000,  1.4000,  0.6000, 17.0000])\n",
      "Sample mean: tensor([ 1.0020,  1.4002,  0.6014, 16.9964])\n",
      "Variance: tensor([0.9500, 1.3020, 0.5820, 2.5500])\n",
      "Sample variance: tensor([0.9444, 1.3104, 0.5847, 2.5478])\n"
     ]
    }
   ],
   "source": [
    "# The mean of the distribution from Pytorch\n",
    "formula_mean = multinomial_dist.mean\n",
    "print(\"Mean: {}\".format(formula_mean))\n",
    "\n",
    "# Our sample mean which denotes the average number of successes\n",
    "sample_mean = samples.mean(axis=0)\n",
    "print(\"Sample mean: {}\".format(sample_mean))\n",
    "\n",
    "# As expected, the two means approximately match and are equal to [num_trials * p1, num_trials * p2, num_trials * pm]\n",
    "\n",
    "\n",
    "# The variance of the distribution from Pytorch\n",
    "formula_var = multinomial_dist.variance\n",
    "print(\"Variance: {}\".format(formula_var))\n",
    "\n",
    "# Our sample variance\n",
    "sample_var = multinomial_dist.sample([num_samples]).var(axis=0)\n",
    "print(\"Sample variance: {}\".format(sample_var))\n",
    "\n",
    "#As expected, the two variances approximately match.\n",
    "assert torch.allclose(formula_var, sample_var, atol=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_probability(X):\n",
    "    assert sum(X) == num_trials\n",
    "    \"\"\"\n",
    "    param: X = [x1, x2, x3, x4] where xi denotes number of occurrences of class i \n",
    "    \"\"\"\n",
    "    matches = samples == torch.tensor(X)\n",
    "    return torch.sum(torch.sum(matches, axis=1) == len(X)) / float(len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0010)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let us find the probability of finding 4 class1, 2 class2, 3 class3 and 11 class4\n",
    "X = [4, 2, 1, 13]\n",
    "find_probability(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0009)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula(X, num_trials, p).exp()\n",
    "# Observe that the value is approximately equal to the value derived from the sample set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
